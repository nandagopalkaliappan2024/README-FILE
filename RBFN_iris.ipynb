{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (108, 4)\n",
      "X_val (27, 4)\n",
      "X_test (15, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=.10)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.2)\n",
    "print('X_train', X_train.shape)\n",
    "print('X_val', X_val.shape)\n",
    "print('X_test', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic',max_iter=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Validasi Training ANN: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "prediksi_val = mlp.predict(X_val)\n",
    "\n",
    "acc_val = accuracy_score(Y_val, prediksi_val)\n",
    "print('Akurasi Validasi Training ANN:', acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Testing ANN: 1.0\n"
     ]
    }
   ],
   "source": [
    "prediksi_test = mlp.predict(X_test)\n",
    "acc_test = accuracy_score(Y_test, prediksi_test)\n",
    "print('Akurasi Testing ANN:', acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Testing ANN: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, plot_confusion_matrix\n",
    "\n",
    "prediksi = mlp.predict(X_test)\n",
    "plot_confusion_matrix(mlp, X_test, Y_test)\n",
    "accuracy = accuracy_score(Y_test, prediksi)\n",
    "print('Akurasi Testing ANN:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train,3)\n",
    "Y_val = to_categorical(Y_val,3)\n",
    "Y_test = to_categorical(Y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - 5s 71ms/step - loss: 1.1989 - acc: 0.2870 - val_loss: 1.0713 - val_acc: 0.2593\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.9949 - acc: 0.3796 - val_loss: 0.9462 - val_acc: 0.5556\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.8892 - acc: 0.6204 - val_loss: 0.8417 - val_acc: 0.5556\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.7577 - acc: 0.6852 - val_loss: 0.7650 - val_acc: 0.5556\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.7028 - acc: 0.7407 - val_loss: 0.6917 - val_acc: 0.7778\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.6484 - acc: 0.7037 - val_loss: 0.6720 - val_acc: 0.5556\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.5806 - acc: 0.9167 - val_loss: 0.5940 - val_acc: 0.9259\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.5452 - acc: 0.7315 - val_loss: 0.5884 - val_acc: 0.6296\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.5165 - acc: 0.8796 - val_loss: 0.5467 - val_acc: 0.9259\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.4941 - acc: 0.7500 - val_loss: 0.5124 - val_acc: 0.9630\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.4628 - acc: 0.9537 - val_loss: 0.5063 - val_acc: 0.8889\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.4482 - acc: 0.7407 - val_loss: 0.4746 - val_acc: 0.9630\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.4318 - acc: 0.9259 - val_loss: 0.4768 - val_acc: 0.8889\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4117 - acc: 0.8056 - val_loss: 0.4514 - val_acc: 0.9630\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.4283 - acc: 0.8148 - val_loss: 0.4618 - val_acc: 0.7778\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4180 - acc: 0.7130 - val_loss: 0.4026 - val_acc: 0.9259\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3832 - acc: 0.8889 - val_loss: 0.4231 - val_acc: 0.9259\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3612 - acc: 0.9167 - val_loss: 0.3963 - val_acc: 0.9630\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3518 - acc: 0.9537 - val_loss: 0.3721 - val_acc: 0.9630\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3425 - acc: 0.9537 - val_loss: 0.3653 - val_acc: 0.9630\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.3317 - acc: 0.9630 - val_loss: 0.3544 - val_acc: 0.9630\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.3234 - acc: 0.9537 - val_loss: 0.3513 - val_acc: 0.9630\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.3200 - acc: 0.9352 - val_loss: 0.3416 - val_acc: 0.9630\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3035 - acc: 0.9722 - val_loss: 0.3373 - val_acc: 0.9630\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2967 - acc: 0.9352 - val_loss: 0.3186 - val_acc: 0.9630\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.2903 - acc: 0.9630 - val_loss: 0.3206 - val_acc: 0.9630\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.2870 - acc: 0.9537 - val_loss: 0.3065 - val_acc: 0.9630\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.2860 - acc: 0.9352 - val_loss: 0.2847 - val_acc: 0.9259\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.2609 - acc: 0.9630 - val_loss: 0.3088 - val_acc: 0.9630\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.2650 - acc: 0.9444 - val_loss: 0.2845 - val_acc: 0.9630\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.2521 - acc: 0.9630 - val_loss: 0.2798 - val_acc: 0.9630\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2503 - acc: 0.9722 - val_loss: 0.2851 - val_acc: 0.9630\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.2471 - acc: 0.9537 - val_loss: 0.2484 - val_acc: 0.9259\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 0.2388 - acc: 0.9537 - val_loss: 0.2853 - val_acc: 0.9630\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.2355 - acc: 0.9722 - val_loss: 0.2482 - val_acc: 0.9630\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2234 - acc: 0.9630 - val_loss: 0.2386 - val_acc: 0.9630\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2181 - acc: 0.9722 - val_loss: 0.2388 - val_acc: 0.9630\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2151 - acc: 0.9630 - val_loss: 0.2352 - val_acc: 0.9630\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.2120 - acc: 0.9722 - val_loss: 0.2189 - val_acc: 0.9630\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2022 - acc: 0.9722 - val_loss: 0.2355 - val_acc: 0.9630\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.2000 - acc: 0.9630 - val_loss: 0.2085 - val_acc: 0.9630\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1990 - acc: 0.9537 - val_loss: 0.2143 - val_acc: 0.9630\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1921 - acc: 0.9630 - val_loss: 0.2088 - val_acc: 0.9630\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1914 - acc: 0.9537 - val_loss: 0.2047 - val_acc: 0.9630\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.1837 - acc: 0.9722 - val_loss: 0.1944 - val_acc: 0.9630\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1793 - acc: 0.9722 - val_loss: 0.2007 - val_acc: 0.9630\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.1796 - acc: 0.9630 - val_loss: 0.1873 - val_acc: 0.9630\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1759 - acc: 0.9537 - val_loss: 0.1782 - val_acc: 0.9630\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.1769 - acc: 0.9630 - val_loss: 0.1966 - val_acc: 0.9630\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1757 - acc: 0.9537 - val_loss: 0.1919 - val_acc: 0.9630\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.1663 - acc: 0.9630 - val_loss: 0.1841 - val_acc: 0.9630\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.1605 - acc: 0.9537 - val_loss: 0.1668 - val_acc: 0.9630\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.1580 - acc: 0.9630 - val_loss: 0.1658 - val_acc: 0.9630\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.1526 - acc: 0.9630 - val_loss: 0.1827 - val_acc: 0.9630\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1514 - acc: 0.9630 - val_loss: 0.1602 - val_acc: 0.9630\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.1571 - acc: 0.9630 - val_loss: 0.1553 - val_acc: 0.9630\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.1580 - acc: 0.9537 - val_loss: 0.1860 - val_acc: 0.9630\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 1s 28ms/step - loss: 0.1584 - acc: 0.9722 - val_loss: 0.1502 - val_acc: 0.9630\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1436 - acc: 0.9630 - val_loss: 0.1614 - val_acc: 0.9630\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1409 - acc: 0.9630 - val_loss: 0.1675 - val_acc: 0.9630\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1425 - acc: 0.9537 - val_loss: 0.1598 - val_acc: 0.9630\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 0.1346 - acc: 0.9630 - val_loss: 0.1494 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.1400 - acc: 0.9444 - val_loss: 0.1711 - val_acc: 0.9630\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.1590 - acc: 0.9444 - val_loss: 0.1451 - val_acc: 0.9630\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1291 - acc: 0.9630 - val_loss: 0.1437 - val_acc: 0.9630\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1386 - acc: 0.9630 - val_loss: 0.1343 - val_acc: 0.9630\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1237 - acc: 0.9630 - val_loss: 0.1469 - val_acc: 0.9630\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1298 - acc: 0.9630 - val_loss: 0.1526 - val_acc: 0.9630\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1423 - acc: 0.9444 - val_loss: 0.1627 - val_acc: 0.9630\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 0.1301 - acc: 0.9630 - val_loss: 0.1282 - val_acc: 0.9259\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1335 - acc: 0.9537 - val_loss: 0.1601 - val_acc: 0.9630\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.1300 - acc: 0.9537 - val_loss: 0.1304 - val_acc: 0.9630\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.1147 - acc: 0.9722 - val_loss: 0.1425 - val_acc: 0.9630\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.1212 - acc: 0.9722 - val_loss: 0.1423 - val_acc: 0.9630\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.1184 - acc: 0.9722 - val_loss: 0.1311 - val_acc: 0.9630\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 0.1133 - acc: 0.9537 - val_loss: 0.1370 - val_acc: 0.9630\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.1193 - acc: 0.9722 - val_loss: 0.1217 - val_acc: 0.9630\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1230 - acc: 0.9630 - val_loss: 0.1640 - val_acc: 0.9630\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 0.1228 - acc: 0.9630 - val_loss: 0.1250 - val_acc: 0.9630\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1192 - acc: 0.9630 - val_loss: 0.1220 - val_acc: 0.9630\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 23ms/step - loss: 0.1058 - acc: 0.9722 - val_loss: 0.1253 - val_acc: 0.9630\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.1052 - acc: 0.9722 - val_loss: 0.1275 - val_acc: 0.9630\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 0.1062 - acc: 0.9722 - val_loss: 0.1224 - val_acc: 0.9630\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.1064 - acc: 0.9630 - val_loss: 0.1224 - val_acc: 0.9630\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.1051 - acc: 0.9630 - val_loss: 0.1140 - val_acc: 0.9630\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1032 - acc: 0.9722 - val_loss: 0.1285 - val_acc: 0.9630\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1041 - acc: 0.9537 - val_loss: 0.1271 - val_acc: 0.9630\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.1022 - acc: 0.9630 - val_loss: 0.1115 - val_acc: 0.9630\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.1051 - acc: 0.9722 - val_loss: 0.1315 - val_acc: 0.9630\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.1223 - acc: 0.9444 - val_loss: 0.1090 - val_acc: 0.9259\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.1044 - acc: 0.9630 - val_loss: 0.1273 - val_acc: 0.9630\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 0.0962 - acc: 0.9722 - val_loss: 0.1116 - val_acc: 0.9630\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.0952 - acc: 0.9630 - val_loss: 0.1158 - val_acc: 0.9630\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0938 - acc: 0.9722 - val_loss: 0.1101 - val_acc: 0.9630\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 0.0955 - acc: 0.9630 - val_loss: 0.1248 - val_acc: 0.9630\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.0975 - acc: 0.9722 - val_loss: 0.1163 - val_acc: 0.9630\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 0.0970 - acc: 0.9722 - val_loss: 0.1183 - val_acc: 0.9630\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 11ms/step - loss: 0.0972 - acc: 0.9722 - val_loss: 0.1115 - val_acc: 0.9630\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 0.0946 - acc: 0.9630 - val_loss: 0.1084 - val_acc: 0.9630\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.0914 - acc: 0.9630 - val_loss: 0.1106 - val_acc: 0.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x42e8caefa0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=100,batch_size=5,validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                320       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 515\n",
      "Trainable params: 515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 348ms/step - loss: 0.0487 - acc: 1.0000\n",
      "Akurasi Testing ANN: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print('Akurasi Testing ANN:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
